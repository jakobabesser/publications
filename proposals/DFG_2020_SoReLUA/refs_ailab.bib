@InProceedings{ofner2020ismir,
  author    = {André Ofner and Sebastian Stober},
  booktitle = {21st International Society for Music Information Retrieval Conference (ISMIR'20)},
  title     = {Modeling perception with hierarchical prediction: Auditory segmentation with deep predictive coding locates candidate evoked potentials in {EEG}},
  year      = {2020},
  timestamp = {2020.10.30},
}


@InProceedings{rane2020icmr,
  author    = {Rane, Roshan Prakash and Sz\"{u}gyi, Edit and Saxena, Vageesh and Ofner, Andr\'{e} and Stober, Sebastian},
  booktitle = {Proceedings of the 2020 International Conference on Multimedia Retrieval},
  title     = {PredNet and Predictive Coding: A Critical Review},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {233–241},
  publisher = {Association for Computing Machinery},
  series    = {ICMR ’20},
  xdoi       = {10.1145/3372278.3390694},
  isbn      = {9781450370875},
  keywords  = {semi-supervised, convolutional neural networks, predictive coding, video prediction, deep learning, video classification},
  location  = {Dublin, Ireland},
  numpages  = {9},
  timestamp = {2020.07.28},
  xurl       = {https://xdoi.org/10.1145/3372278.3390694},
}

@InProceedings{ofner2020smc,
  author    = {André Ofner and Sebastian Stober},
  booktitle = {IEEE International Conference on Systems, Man, and Cybernetics (SMC 2020)},
  title     = {Balancing Active Inference and Active Learning with Deep Variational Predictive Coding for {EEG}},
  year      = {2020},
  timestamp = {2020.07.28},
}

@Article{ofner2019alife,
  author    = {Ofner, André and Stober, Sebastian},
  journal   = {The 2019 Conference on Artificial Life},
  title     = {Hybrid Variational Predictive Coding as a Bridge between Human and Artificial Cognition},
  year      = {2019},
  number    = {31},
  pages     = {68-69},
  abstract  = {Predictive coding and its generalization to active inference offer a unified theory of brain function. The underlying predictive processing paradigmhas gained significant attention in artificial intelligence research for its representation learning and predictive capacity. Here, we suggest that it is possible to integrate human and artificial generative models with a predictive coding network that processes sensations simultaneously with the signature of predictive coding found in human neuroimaging data. We propose a recurrent hierarchical predictive coding model that predicts low-dimensional representations of stimuli, electroencephalogram and physiological signals with variational inference. We suggest that in a shared environment, such hybrid predictive coding networks learn to incorporate the human predictive model in order to reduce prediction error. We evaluate the model on a publicly available EEG dataset of subjects watching one-minute long video excerpts. Our initial results indicate that the model can be trained to predict visual properties such as the amount, distance and motion of human subjects in videos.},
  xdoi       = {10.1162/isal\_a\_00142},
  eprint    = {https://www.mitpressjournals.org/xdoi/pdf/10.1162/isal_a_00142},
  pdf       = {ofner2019alife.pdf},
  poster    = {ofner2019alife-slides.pdf},
  sortkey   = {ao2},
  timestamp = {2019.11.18},
  xurl       = {https://www.mitpressjournals.org/xdoi/abs/10.1162/isal_a_00142},
}

@InProceedings{ofner2018hpc,
  author    = {André Ofner and Sebastian Stober},
  title     = {Towards Bridging Human and Artificial Cognition: Hybrid Variational Predictive Coding of the Physical World, the Body and the Brain},
  booktitle = {NeurIPS 2018 Workshop on Modeling the Physical World},
  year      = {2018},
  abstract  = {Predictive coding and its generalization to active inference offer a unified theory of brain function. The underlying predictive processing paradigm has gained significant attention within the machine learning community for its representation learning and predictive capacity. Here, we suggest that it is possible to integrate human and artificial predictive models with an artificial neural network that learns to predict sensations simultaneously with their representation in the brain. Guided by the principles of active inference, we propose a recurrent hierarchical predictive coding model that jointly predicts stimuli, electroencephalogram and physiological signals under variational inference. We suggest that in a shared environment, the artificial inference process can learn to predict and exploit the human generative model. We evaluate the model on a publicly available dataset of subjects watching one-minute long video excerpts and show that the model can be trained to predict physical properties such as the amount, distance and motion of human subjects in future frames of the videos. Our results hint at the possibility of bi-directional active inference across human and machine.},
  pdf       = {ofner2018hpc.pdf},
  poster    = {ofner2018hpc-poster.pdf},
  sortkey   = {an6},
  timestamp = {2018.11.22},
}

@InProceedings{rane2019comco,
  author    = {Roshan Prakash Rane and André Ofner and Shreyas Gite and Sebastian Stober},
  booktitle = {Computational Cognition 2019 Workshop},
  title     = {Predictive Coding Based Vision For Autonomous Cars},
  year      = {2019},
  abstract  = {In recent decades, Predictive Coding has emerged as a unifying theory of human cognition. Related theories in cognitive neuroscience, such as Active Inference and Free Energy Minimization, have demonstrated that Predictive Coding can account for many aspects of human perception and action. However, little work has been done to explore the Predictive Coding framework in the practical domains like computer vision or robotics.
A popular implementation in the field of computer vision that is inspired by Predictive Coding is called the ‘PredNet’. PredNet is trained on videos to perform future frame prediction. In a purely perceptual setup like this, Predictive Coding is defined as a hierarchical generative model that dynamically infers low-dimensional causes from high-dimensional perceptual stimuli. The architecture is trained at each level of it’s hierarchy to learn low-dimensional causal factors from temporal visual data by actively generating top-down predictions or hypotheses and testing them against bottom-up incoming frames or sensory evidence. In our recent work, we inspected the PredNet architecture and found that it fails to emulate and therefore benefit from many core ideas of Predictive Coding. We will highlight these conceptual limitations of PredNet and present preliminary results from our improved Predictive Coding architecture.
Even though our architecture is inspired by PredNet, it differs from it in three main ways: (1) It is designed to perform semantic segmentation which is an important vision task for autonomous driving. The task is to classify pixels of an image as belonging to a semantic category like drivable road, pedestrian or car (2) The top-down predictions represent semantic class maps and not pixel values and (3) It performs not just short-term but also long-term predictions along its hierarchy.
Finally, we compare our architecture’s performance against contemporary deep learning methods for the autonomous driving vision task. We access the semantic segmentation accuracy with an emphasis on the computational efficiency. This includes the model size, amount of training data it needs and the run-time. We also inspect the ability of the model to adjust to differing visual contexts like day time, night time and different weather conditions like rain or snow.},
  poster    = {rane2019comco-poster.pdf},
  sortkey   = {ao7},
  timestamp = {2019.11.19},
  xurl       = {http://www.comco2019.com/abstracts/day1_rane.pdf},
}

@InProceedings{krug2018irasl,
  author    = {Andreas Krug and René Knaebel and Sebastian Stober},
  title     = {Neuron Activation Profiles for Interpreting Convolutional Speech Recognition Models},
  booktitle = {NeurIPS 2018 Interpretability and Robustness for Audio, Speech and Language Workshop (IRASL'18)},
  year      = {2018},
  abstract  = {The increasing complexity of deep Artificial Neural Networks (ANNs) allows to solve complex tasks in various applications. This comes with less understanding of decision processes in ANNs. Therefore, introspection techniques have been proposed to interpret how the network accomplishes its task. Those methods mostly visualize their results in the input domain and often only process single samples. For images, highlighting important features or creating inputs which activate certain neurons is intuitively interpretable. The same introspection for speech is much harder to interpret. In this paper, we propose an alternative method which analyzes neuron activations for whole data sets. Its generality allows application to complex data like speech. We introduce time-independent Neuron Activation Profiles (NAPs) as characteristic network responses to certain groups of inputs. By clustering those time-independent NAPs, we reveal that layers are specific to certain groups. We demonstrate our method for a fully-convolutional speech recognizer. There, we investigate whether phonemes are implicitly learned as an intermediate representation for predicting graphemes. We show that our method reveals, which layers encode phonemes and graphemes and that similarities between phonetic categories are reflected in the clustering of time-independent NAPs.},
  pdf       = {krug2018irasl.pdf},
  slides    = {krug2018irasl-slides.pdf},
  sortkey   = {an5},
  timestamp = {2018.11.21},
}

@InProceedings{krug2019blackboxnlp,
  author    = {Andreas Krug and Sebastian Stober},
  title     = {Visualizing Deep Neural Networks for Speech Recognition with Learned Topographic Filter Maps},
  booktitle = {Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP},
  year      = {2019},
  abstract  = {The uninformative ordering of artificial neurons in Deep Neural Networks complicates visualizing activations in deeper layers. This is one reason why the internal structure of such models is very unintuitive. In neuroscience, activity of real brains can be visualized by highlighting active regions. Inspired by those techniques, we train a convolutional speech recognition model, where filters are arranged in a 2D grid and neighboring filters are similar to each other. We show, how those topographic filter maps visualize artificial neuron activations more intuitively. Moreover, we investigate, whether this causes phoneme-responsive neurons to be grouped in certain regions of the topographic map.},
  pdf       = {krug2019blackboxnlp.pdf},
  sortkey   = {ao5},
  timestamp = {2019.11.18},
}

@inproceedings{krug2017ccn,
  author = {Andreas Krug and Sebastian Stober},
  title = {Adaptation of the Event-Related Potential Technique for Analyzing Artificial Neural Nets},
  booktitle = {Conference on Cognitive Computational Neuroscience (CCN'17)},
  year = {2017}
}

@article{krug2020gradient,
  title={Gradient-Adjusted Neuron Activation Profiles for Comprehensive Introspection of Convolutional Speech Recognition Models},
  author={Krug, Andreas and Stober, Sebastian},
  journal={arXiv preprint arXiv:2002.08125},
  year={2020}
}





@inproceedings{engel2020ddsp,
  title={DDSP: Differentiable Digital Signal Processing},
  author={Jesse Engel and Lamtharn Hantrakul and Chenjie Gu and Adam Roberts},
  booktitle={ICLR},
  year={2020}
}

@ARTICLE{8022871,
  author={M. {Kahng} and P. Y. {Andrews} and A. {Kalro} and D. H. {Chau}},
  journal={IEEE Trans. on Visualization and Computer Graphics},
  title={ActiVis: Visual Exploration of Industry-Scale Deep Neural Network Models},
  year={2018},
  volume={24},
  number={1},
  pages={88-97},
  abstract={While deep learning models have achieved state-of-the-art accuracies for many prediction tasks, understanding these models remains a challenge. Despite the recent interest in developing visual tools to help users interpret deep learning models, the complexity and wide variety of models deployed in industry, and the large-scale datasets that they used, pose unique design challenges that are inadequately addressed by existing work. Through participatory design sessions with over 15 researchers and engineers at Facebook, we have developed, deployed, and iteratively improved ActiVis, an interactive visualization system for interpreting large-scale deep learning models and results. By tightly integrating multiple coordinated views, such as a computation graph overview of the model architecture, and a neuron activation view for pattern discovery and comparison, users can explore complex deep neural network models at both the instance-and subset-level. ActiVis has been deployed on Facebook's machine learning platform. We present case studies with Facebook researchers and engineers, and usage scenarios of how ActiVis may work with different models.},
  keywords={data visualisation;learning (artificial intelligence);neural nets;visual tools;large-scale datasets;participatory design sessions;interactive visualization system;large-scale deep learning models;model architecture;complex deep neural network models;visual exploration;industry-scale deep neural network models;ActiVis system;machine learning platform;Computational modeling;Tools;Machine learning;Data models;Neurons;Facebook;Data visualization;Visual analytics;deep learning;machine learning;information visualization},
  xdoi={10.1109/TVCG.2017.2744718},
  ISSN={1941-0506},
  month={Jan},}


@ARTICLE{8957135,
  author={A. {Bichicchi} and R. {Belaroussi} and A. {Simone} and V. {Vignali} and C. {Lantieri} and X. {Li}},
  journal={IEEE Access},
  title={Analysis of Road-User Interaction by Extraction of Driver Behavior Features Using Deep Learning},
  year={2020},
  volume={8},
  number={},
  pages={19638-19645},
  abstract={In this study, an improved deep learning model is proposed to explore the complex interactions between the road environment and driver's behaviour throughout the generation of a graphical representation. The proposed model consists of an unsupervised Denoising Stacked Autoencoder (SDAE) able to provide output layers in RGB colors. The dataset comes from an experimental driving test where kinematic measures were tracked with an in-vehicle GPS device. The graphical outcomes reveal the method ability to efficiently detect patterns of simple driving behaviors, as well as the road environment complexity and some events encountered along the path.},
  keywords={behavioural sciences computing;Global Positioning System;learning (artificial intelligence);neural nets;traffic engineering computing;pattern detection;driver behavior feature extraction;unsupervised denoising stacked autoencoder;road environment complexity;driving behaviors;graphical outcomes;in-vehicle GPS device;kinematic measures;experimental driving test;RGB colors;output layers;graphical representation;complex interactions;improved deep learning model;road-user interaction;Feature extraction;Vehicles;Roads;Image color analysis;Principal component analysis;Data models;Data mining;Deep learning;driver behavior;event detection;road safety;workload},
  xdoi={10.1109/ACCESS.2020.2965940},
  ISSN={2169-3536},
  month={},}


@inproceedings{10.1145/3109859.3109877,
author = {Donkers, Tim and Loepp, Benedikt and Ziegler, J\"{u}rgen},
title = {Sequential User-Based Recurrent Neural Network Recommendations},
year = {2017},
isbn = {9781450346528},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
xurl = {https://xdoi.org/10.1145/3109859.3109877},
xdoi = {10.1145/3109859.3109877},
booktitle = {Proceedings of the Eleventh ACM Conference on Recommender Systems},
pages = {152–160},
numpages = {9},
keywords = {recurrent neural networks, recommender systems, neural networks, deep learning, sequential recommendations},
location = {Como, Italy},
series = {RecSys ’17}
}

@inproceedings{10.1145/2766462.2767745,
author = {Lagun, Dmitry and Agichtein, Eugene},
title = {Inferring Searcher Attention by Jointly Modeling User Interactions and Content Salience},
year = {2015},
isbn = {9781450336215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
xurl = {https://xdoi.org/10.1145/2766462.2767745},
xdoi = {10.1145/2766462.2767745},
booktitle = {Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {483–492},
numpages = {10},
keywords = {web page layout, mouse cursor tracking, searcher attention, eye tracking, content salience, search behavior},
location = {Santiago, Chile},
series = {SIGIR ’15}
}

@inproceedings{10.1145/2647868.2654945,
author = {Lin, Huijie and Jia, Jia and Guo, Quan and Xue, Yuanyuan and Li, Qi and Huang, Jie and Cai, Lianhong and Feng, Ling},
title = {User-Level Psychological Stress Detection from Social Media Using Deep Neural Network},
year = {2014},
isbn = {9781450330633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
xurl = {https://xdoi.org/10.1145/2647868.2654945},
xdoi = {10.1145/2647868.2654945},
booktitle = {Proceedings of the 22nd ACM International Conference on Multimedia},
pages = {507–516},
numpages = {10},
keywords = {stress detection, cross auto encoders, convolutional neural network, micro-blog, social media, deep learning},
location = {Orlando, Florida, USA},
series = {MM ’14}
}

@inproceedings{swearngin2019modeling,
  title={Modeling Mobile Interface Tappability Using Crowdsourcing and Deep Learning},
  author={Swearngin, Amanda and Li, Yang},
  booktitle={Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
  pages={1--11},
  year={2019}
}

@article{budd2019survey,
  title={A Survey on Active Learning and Human-in-the-Loop Deep Learning for Medical Image Analysis},
  author={Budd, Samuel and Robinson, Emma C and Kainz, Bernhard},
  journal={arXiv preprint arXiv:1910.02923},
  year={2019}
}



@article{hinton2006autoencoders,
  title={Reducing the dimensionality of data with neural networks},
  author={Hinton, Geoffrey E and Salakhutdinov, Ruslan R},
  journal={science},
  volume={313},
  number={5786},
  pages={504--507},
  year={2006},
  publisher={American Association for the Advancement of Science}
}

@article{vincent2010stacked,
  title={Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion.},
  author={Vincent, Pascal and Larochelle, Hugo and Lajoie, Isabelle and Bengio, Yoshua and Manzagol, Pierre-Antoine and Bottou, L{\'e}on},
  journal={Journal of machine learning research},
  volume={11},
  number={12},
  year={2010}
}

@inproceedings{baldi2012autoencoders,
  title={Autoencoders, unsupervised learning, and deep architectures},
  author={Baldi, Pierre},
  booktitle={Proceedings of ICML workshop on unsupervised and transfer learning},
  pages={37--49},
  year={2012}
}

@article{salakhutdinov2015learning,
  title={Learning deep generative models},
  author={Salakhutdinov, Ruslan},
  journal={ANNU REV STAT APPL},
  volume={2},
  pages={361--385},
  year={2015},
  publisher={Annual Reviews}
}

@inproceedings{kingma2013vae,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  xjournal={International Conference on Learning Representations (ICLR'14)},
  booktitle={ICLR},
  year={2014}
}

@inproceedings{rezende2014vae,
  title={Stochastic backpropagation and variational inference in deep latent gaussian models},
  author={Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
  xbooktitle={International Conference on Machine Learning (ICML'14)},
  booktitle={ICML},
  year={2014}
}

@inproceedings{vandenoord2017vqvae,
  title={Neural discrete representation learning},
  author={van den Oord, Aaron and Vinyals, Oriol and others},
  booktitle={NeurIPS},
  pages={6306--6315},
  year={2017}
}

@inproceedings{gregor2018tdvae,
  title={Temporal Difference Variational Auto-Encoder},
  author={Gregor, Karol and Papamakarios, George and Besse, Frederic and Buesing, Lars and Weber, Theophane},
  zbooktitle={International Conference on Learning Representations (ICLR'18)},
  booktitle={ICLR},
  year={2018}
}

@inproceedings{razavi2019vqvae2,
  title={Generating diverse high-fidelity images with {VQ-VAE-2}},
  author={Razavi, Ali and v d Oord, Aaron and Vinyals, Oriol},
  xbooktitle={Advances in Neural Information Processing Systems (NeurIPS'19)},
  booktitle={NeurIPS},
  pages={14866--76},
  year={2019}
}

@article{tsai2020demystifying,
  title={Demystifying Self-Supervised Learning: An Information-Theoretical Framework},
  author={Tsai, Yao-Hung Hubert and Wu, Yue and Salakhutdinov, Ruslan and Morency, Louis-Philippe},
  journal={arXiv preprint arXiv:2006.05576},
  year={2020}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{lan2019albert,
  title={Albert: A lite bert for self-supervised learning of language representations},
  author={Lan, Zhenzhong and Chen, Mingda and Goodman, Sebastian and Gimpel, Kevin and Sharma, Piyush and Soricut, Radu},
  journal={arXiv preprint arXiv:1909.11942},
  year={2019}
}

@inproceedings{tung2017self,
  title={Self-supervised learning of motion capture},
  author={Tung, Hsiao-Yu and Tung, Hsiao-Wei and Yumer, Ersin and Fragkiadaki, Katerina},
  xbooktitle={Advances in Neural Information Processing Systems (NeurIPS'17)},
  booktitle={NeurIPS},
  pages={5236--5246},
  year={2017}
}

@inproceedings{zhai2019s4l,
  title={S4l: Self-supervised semi-supervised learning},
  author={Zhai, Xiaohua and Oliver, Avital and Kolesnikov, Alexander and Beyer, Lucas},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1476--1485},
  year={2019}
}

@article{jing2020self,
  title={Self-supervised visual feature learning with deep neural networks: A survey},
  author={Jing, Longlong and Tian, Yingli},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2020},
  publisher={IEEE}
}

@INPROCEEDINGS{sermanet2018timecontrastive,
  author={P. {Sermanet} and C. {Lynch} and Y. {Chebotar} and J. {Hsu} and E. {Jang} and S. {Schaal} and S. {Levine} and G. {Brain}},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Time-Contrastive Networks: Self-Supervised Learning from Video}, 
  year={2018},
  volume={},
  number={},
  pages={1134-1141},
  abstract={We propose a self-supervised approach for learning representations and robotic behaviors entirely from unlabeled videos recorded from multiple viewpoints, and study how this representation can be used in two robotic imitation settings: imitating object interactions from videos of humans, and imitating human poses. Imitation of human behavior requires a viewpoint-invariant representation that captures the relationships between end-effectors (hands or robot grippers) and the environment, object attributes, and body pose. We train our representations using a triplet loss, where multiple simultaneous viewpoints of the same observation are attracted in the embedding space, while being repelled from temporal neighbors which are often visually similar but functionally different. This signal causes our model to discover attributes that do not change across viewpoint, but do change across time, while ignoring nuisance variables such as occlusions, motion blur, lighting and background. We demonstrate that this representation can be used by a robot to directly mimic human poses without an explicit correspondence, and that it can be used as a reward function within a reinforcement learning algorithm. While representations are learned from an unlabeled collection of task-related videos, robot behaviors such as pouring are learned by watching a single 3rd-person demonstration by a human. Reward functions obtained by following the human demonstrations under the learned representation enable efficient reinforcement learning that is practical for real-world robotic systems. Video results, open-source code and dataset are available at sermanet.github.io/imitate.},
  keywords={image representation;learning (artificial intelligence);pose estimation;robot programming;robot vision;video signal processing;time-contrastive networks;robotic behaviors;robotic imitation settings;human poses;viewpoint-invariant representation;end-effectors;reinforcement learning algorithm;self-supervised learning;robotic systems;Robots;Task analysis;Visualization;Learning (artificial intelligence);Training;Liquids;Lighting},
  xdoi={10.1109/ICRA.2018.8462891},
  ISSN={2577-087X},
  month={05},}

@inproceedings{lee2019making,
  title={Making sense of vision and touch: Self-supervised learning of multimodal representations for contact-rich tasks},
  author={Lee, Michelle A and Zhu, Yuke and Srinivasan, Krishnan and Shah, Parth and Savarese, Silvio and Fei-Fei, Li and Garg, Animesh and Bohg, Jeannette},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={8943--8950},
  year={2019},
  organization={IEEE}
}



@InProceedings{dwibedi2019temporal,
author = {Dwibedi, Debidatta and Aytar, Yusuf and Tompson, Jonathan and Sermanet, Pierre and Zisserman, Andrew},
title = {Temporal Cycle-Consistency Learning},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {06},
year = {2019}
}



@InProceedings{saunshi19contrastive,
  title =    {A Theoretical Analysis of Contrastive Unsupervised Representation Learning},
  author =   {Saunshi, Nikunj and Plevrakis, Orestis and Arora, Sanjeev and Khodak, Mikhail and Khandeparkar, Hrishikesh},
  booktitle =    {Proceedings of the 36th International Conference on Machine Learning},
  pages =    {5628--5637},
  year =   {2019},
  editor =   {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume =   {97},
  series =   {Proceedings of Machine Learning Research},
  address =    {Long Beach, California, USA},
  month =    {06},
  publisher =    {PMLR},
  pdf =    {http://proceedings.mlr.press/v97/saunshi19a/saunshi19a.pdf},
  xurl =    {http://proceedings.mlr.press/v97/saunshi19a.html},
  abstract =   {Recent empirical works have successfully used unlabeled data to learn feature representations that are broadly useful in downstream classification tasks. Several of these methods are reminiscent of the well-known word2vec embedding algorithm: leveraging availability of pairs of semantically “similar" data points and “negative samples," the learner forces the inner product of representations of similar pairs with each other to be higher on average than with negative samples. The current paper uses the term \emph{contrastive learning} for such algorithms and presents a theoretical framework for analyzing them by introducing \emph{latent classes} and hypothesizing that semantically similar points are sampled from the same latent class. This framework allows us to show provable guarantees on the performance of the learned representations on the average classification task that is comprised of a subset of the same set of latent classes. Our generalization bound also shows that learned representations can reduce (labeled) sample complexity on downstream tasks. We conduct controlled experiments in both the text and image domains to support the theory.}
}

@article{huang2011predictive,
  title={Predictive coding},
  author={Huang, Yanping and Rao, Rajesh PN},
  journal={Wiley Interdisciplinary Reviews: Cognitive Science},
  volume={2},
  number={5},
  pages={580--593},
  year={2011},
  publisher={Wiley Online Library}
}


@article{bongjun2018soundevent,
author = {Kim, Bongjun and Pardo, Bryan},
title = {A Human-in-the-Loop System for Sound Event Detection and Annotation},
year = {2018},
issue_date = {July 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
issn = {2160-6455},
xurl = {https://xdoi.org/10.1145/3214366},
xdoi = {10.1145/3214366},
journal = {ACM Trans. Interact. Intell. Syst.},
month = jun,
articleno = {13},
numpages = {23},
keywords = {human-in-the-loop system, sound event detection, Interactive machine learning}
}

@article{lorbach2019interactive,
  title={Interactive rodent behavior annotation in video using active learning},
  author={Lorbach, Malte and Poppe, Ronald and Veltkamp, Remco C},
  journal={Multimedia Tools and Applications},
  volume={78},
  number={14},
  pages={19787--19806},
  year={2019},
  publisher={Springer}
}

@book{lang2017handbook,
  title={Handbook of learning analytics},
  author={Lang, Charles and Siemens, George and Wise, Alyssa and Gasevic, Dragan},
  year={2017},
  publisher={SOLAR, Society for Learning Analytics and Research}
}

@article{liu2017going,
  title={Going beyond better data prediction to create explanatory models of educational data},
  author={Liu, Ran and Koedinger, Kenneth R},
  journal={The Handbook of learning analytics},
  pages={69--76},
  year={2017}
}

@article{rose2019explanatory,
  title={Explanatory learner models: Why machine learning (alone) is not the answer},
  author={Ros{\'e}, Carolyn P and McLaughlin, Elizabeth A and Liu, Ran and Koedinger, Kenneth R},
  journal={British Journal of Educational Technology},
  volume={50},
  number={6},
  pages={2943--2958},
  year={2019},
  publisher={Wiley Online Library}
}

@article{du2020integrated,
  title={An integrated framework based on latent variational autoencoder for providing early warning of at-risk students},
  author={Du, Xu and Yang, Juan and Hung, Jui-Long},
  journal={IEEE Access},
  volume={8},
  pages={10110--10122},
  year={2020},
  publisher={IEEE}
}

@article{yang2020using,
  title={Using Convolutional Neural Network to Recognize Learning Images for Early Warning of At-risk Students},
  author={Yang, Zongkai and Yang, Juan and Rice, Kerry and Hung, Jui-Long and Du, Xu},
  journal={IEEE Transactions on Learning Technologies},
  year={2020},
  publisher={IEEE}
}

@inproceedings{cen2006learning,
  title={Learning factors analysis--a general method for cognitive model evaluation and improvement},
  author={Cen, Hao and Koedinger, Kenneth and Junker, Brian},
  booktitle={International Conference on Intelligent Tutoring Systems},
  pages={164--175},
  year={2006},
  organization={Springer}
}

@inproceedings{EditBlog,
   author =       {MIke Jeffs},
   title =        {OK Google, Siri, Alexa, Cortana; Can you tell me some stats on voice search?},
   publisher =    {The Editr Blog},
   month =        {01},
   year =         {20178},
   note =         {[Online; posted 8th-Jan-2018]},
 }xurl =          {https://edit.co.uk/blog/google-voice-search-stats-growth-trends/},

@inproceedings{eMarketer2019,
   author =       {V. Petrock},
   title =        {US Voice Assistant Users 2019 -- Who, What, Where and Why},
   publisher =    {eMarketer},
   month =        {09},
   year =         {2019},
   note =         {[Online; 15-Jul-2019]},
 }xurl =          {https://www.emarketer.com/content/us-voice-assistant-users-2019#page-report},
 
 @inproceedings{voicebot.ai2019,
   author =       {Bret Kinsella},
   title =        {Nearly 90 Million U.S. Adults Have Smart Speakers, Adoption Now Exceeds One-Third of Consumers},
   publisher =    {voicebot.ai},
   month =        {04},
   year =         {2020},
   note =         {[Online;  April 28, 2020 at 12:19 pm]},
 }xurl =          {https://voicebot.ai/2020/04/28/nearly-90-million-u-s-adults-have-smart-speakers-adoption-now-exceeds-one-third-of-consumers/},
 
 @Article{AI_55,
  Title                    = {Siri, Siri, in my hand: Who’s the fairest in the land? On the interpretations, illustrations, and implications of artificial intelligence},
  Author                   = {A. Kaplan and M. Haenlein},
  Journal                  = {Business Horizons},
  Volume                   = {62},
  Year                     = {2019},
  pages                    = {15--25},
}

@techreport{Valli_NotesOnNI,
     title = {Notes on Natural Interaction},
     author = {Valli, Alessandro},
     year = {2007},
     institution = {University of Florence, Italy},
     month = {09},
}

@Inbook{Companion2017,
author="Biundo, Susanne
and Wendemuth, Andreas",
title="An introduction to companion-technology",
bookTitle="Companion Technology: A Paradigm Shift in Human-Technology Interaction",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="1--15",
isbn="978-3-319-43665-4",
}

@article{Alepis2017MonkeySM,
  title={Monkey Says, Monkey Does: Security and Privacy on Voice Assistants},
  author={E. Alepis and C. Patsakis},
  journal={IEEE Access},
  year={2017},
  volume={5},
  pages={17841--17851}
}

@article{UBICOMM34,
  title={A study of security and privacy issues associated with the Amazon Echo},
  author={C. Jackson and A. Orebaugh},
  journal={International Journal of Internet of Things and Cyber-Assurance},
  year={2018},
  volume={1}, 
  number={1}, 
  pages={91--100}
}


@article{NAUTSCH2019441,
title = {Preserving privacy in speaker and speech characterisation},
journal = {COMPUT SPEECH LANG},
pages = {441-80},
year = {2019},
issn = {0885-2308},
xdoi = {https://xdoi.org/10.1016/j.csl.2019.06.001},
xurl = {http://www.sciencedirect.com/science/article/pii/S0885230818303875},
author = {Andreas Nautsch and Abelino Jiménez and Amos Treiber and Jascha Kolberg and Catherine Jasserand and Els Kindt and Héctor Delgado and Massimiliano Todisco and Mohamed Amine Hmani and Aymen Mtibaa and Mohammed Ahmed Abdelraheem and Alberto Abad and Francisco Teixeira and Driss Matrouf and Marta Gomez-Barrero and Dijana Petrovska-Delacrétaz and Gérard Chollet and Nicholas Evans and Thomas Schneider and Jean-François Bonastre and Bhiksha Raj and Isabel Trancoso and Christoph Busch},
}

@article{tomashenko2020introducing,
  author    = {Natalia Tomashenko and Brij Mohan Lal Srivastava and Xin Wang and Emmanuel Vincent and Andreas Nautsch and Junichi Yamagishi and Nicholas Evans and Jose Patino and Jean-François Bonastre and Paul-Gauthier Noé and Massimiliano Todisco},
  title     = {Introducing the VoicePrivacy Initiative},
  year      = {2020},
  xurl       = {https://arxiv.org/pdf/2005.01387v2.pdf},
  journal={arXiv preprint 2005.01387},
}

@ARTICLE{5353689,
  author={D. {Erro} and A. {Moreno} and A. {Bonafonte}},
  journal={IEEE Transactions on Audio, Speech, and Language Processing}, 
  title={INCA Algorithm for Training Voice Conversion Systems From Nonparallel Corpora}, 
  year={2010},
  volume={18},
  number={5},
  pages={944-953},
}

@INPROCEEDINGS{7552917,  
author={L. {Sun} and K. {Li} and H. {Wang} and S. {Kang} and H. {Meng}},  
booktitle={2016 IEEE International Conference on Multimedia and Expo (ICME)},  
title={Phonetic posteriorgrams for many-to-one voice conversion without parallel data training},   year={2016}, 
volume={},  
number={},  
pages={1-6},
}

@inproceedings{XieSL16,
  author    = {Feng{-}Long Xie and
               Frank K. Soong and
               Haifeng Li},
  title     = {A {KL} Divergence and DNN-Based Approach to Voice Conversion without
               Parallel Training Sentences},
  booktitle = {Proc. of Interspeech 2016},
  pages     = {287--291},
  publisher = {{ISCA}},
  year      = {2016},
}

@INPROCEEDINGS{7820786,
  author={C. {Hsu} and H. {Hwang} and Y. {Wu} and Y. {Tsao} and H. {Wang}},
  booktitle={2016 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA)}, 
  title={Voice conversion from non-parallel corpora using variational auto-encoder}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},}

@INPROCEEDINGS{7820901,
  author={J. {Wu} and Z. {Wu} and L. {Xie}},
  booktitle={APSIPA'16}, 
  title={On the use of I-vectors and average voice model for voice conversion without parallel data}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},}
  
  
  @article{HsuHWTW17,
  author    = {Chin{-}Cheng Hsu and
               Hsin{-}Te Hwang and
               Yi{-}Chiao Wu and
               Yu Tsao and
               Hsin{-}Min Wang},
  title     = {Voice Conversion from Unaligned Corpora using Variational Autoencoding
               Wasserstein Generative Adversarial Networks},
  year      = {2017},
  xurl       = {http://arxiv.org/abs/1704.00849},
  journal={arXiv preprint 1704.00849},
}

@inproceedings{Lorenzo-TruebaF18,
  author    = {Jaime Lorenzo{-}Trueba and
               Fuming Fang and
               Xin Wang and
               Isao Echizen and
               Junichi Yamagishi and
               Tomi Kinnunen},
  title     = {Can we steal your vocal identity from the Internet?: Initial investigation
               of cloning Obama's voice using GAN, WaveNet and low-quality found
               data},
  booktitle = {Odyssey'18: The Speaker and Language Recognition Workshop},
  pages     = {240--47},
  year      = {2018},
  xurl       = {https://xdoi.org/10.21437/Odyssey.2018-34},
  xdoi       = {10.21437/Odyssey.2018-34},
  timestamp = {Mon, 15 Apr 2019 10:35:34 +0200},
  bibxurl    = {https://dblp.org/rec/conf/odyssey/Lorenzo-TruebaF18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

  @article{Hirokazu18,
  author    = {Hirokazu Kameoka and Takuhiro Kaneko and Kou Tanaka and Nobukatsu Hojo},
  title     = {StarGAN-VC: Non-parallel many-to-many voice conversion with star generative adversarial networks},
  journal={arXiv preprint 1806.02169},
  year      = {2018},
  xurl       = {https://arxiv.org/abs/1806.02169},
}

@article{Oord2016WaveNetAG,
  title={WaveNet: A Generative Model for Raw Audio},
  author={A. Oord and S. Dieleman and H. Zen and K. Simonyan and Oriol Vinyals and A. Graves and Nal Kalchbrenner and A. Senior and K. Kavukcuoglu},
  year={2016},
  journal={arXiv preprint 1609.03499}
}



@inproceedings{HuangWHTHKTTW19,
  author    = {Wen{-}Chin Huang and
               Yi{-}Chiao Wu and
               Hsin{-}Te Hwang and
               Patrick Lumban Tobing and
               Tomoki Hayashi and
               Kazuhiro Kobayashi and
               Tomoki Toda and
               Yu Tsao and
               Hsin{-}Min Wang},
  title     = {Refined WaveNet Vocoder for Variational Autoencoder Based Voice Conversion},
  booktitle = {27th European Signal Processing Conference, {EUSIPCO} 2019, {A} Coru{\~{n}}a,
               Spain, September 2-6, 2019},
  pages     = {1--5},
  publisher = {{IEEE}},
  year      = {2019},
  xurl       = {https://xdoi.org/10.23919/EUSIPCO.2019.8902651},
  xdoi       = {10.23919/EUSIPCO.2019.8902651},
  timestamp = {Fri, 20 Dec 2019 16:00:32 +0100},
  bibxurl    = {https://dblp.org/rec/conf/eusipco/HuangWHTHKTTW19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{8683143,
  author={R. {Prenger} and R. {Valle} and B. {Catanzaro}},
  booktitle={ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Waveglow: A Flow-based Generative Network for Speech Synthesis}, 
  year={2019},
  volume={},
  number={},
  pages={3617-3621},}

@INPROCEEDINGS{8639507,
  author={B. {Sisman} and M. {Zhang} and S. {Sakti} and H. {Li} and S. {Nakamura}},
  booktitle={2018 IEEE Spoken Language Technology Workshop (SLT)}, 
  title={Adaptive Wavenet Vocoder for Residual Compensation in GAN-Based Voice Conversion}, 
  year={2018},
  volume={},
  number={},
  pages={282-289},}

@article{ZHANG202031,
title = "DeepConversion: Voice conversion with limited parallel training data",
journal = "Speech Communication",
volume = "122",
pages = "31 - 43",
year = "2020",
issn = "0167-6393",
xdoi = "https://xdoi.org/10.1016/j.specom.2020.05.004",
xurl = "http://www.sciencedirect.com/science/article/pii/S0167639320302296",
author = "Mingyang Zhang and Berrak Sisman and Li Zhao and Haizhou Li",
}


@article{pal2019study,
  title={A study of semi-supervised speaker diarization system using gan mixture model},
  author={Monisankha Pal and Manoj Kumar and Raghuveer Peri and Shrikanth Narayanan},
  journal={arXiv:1910.11416},
  year={2019}
}

@INPROCEEDINGS{8682064,
  author={G. {Bhattacharya} and J. {Monteiro} and J. {Alam} and P. {Kenny}},
  booktitle={Proc. of IEEE ICASSP'19}, 
  title={Generative Adversarial Speaker Embedding Networks for Domain Robust End-to-end Speaker Verification}, 
  year={2019},
  volume={},
  number={},
  pages={6226-6230},}

@article{chung2018voxceleb2,
    title={VoxCeleb2: Deep Speaker Recognition},
    author={Joon Son Chung and Arsha Nagrani and Andrew Zisserman},
    year={2018},
    journal={arXiv preprint 1806.05622},
}

@article{ali2018DBN,
author = {Ali, Hazrat and Tran, Son and Benetos, Emmanouil and Garcez, Artur},
year = {2018},
month = {03},
pages = {},
title = {Speaker Recognition with Hybrid Features from a Deep Belief Network},
journal = {Neural Computing and Applications},
xdoi = {10.1007/s00521-016-2501-7}
}

@inproceedings{snyder2018xvec,
author = {Snyder, David and Garcia-Romero, Daniel and Sell, Gregory and Povey, Daniel and Khudanpur, Sanjeev},
year = {2018},
month = {04},
pages = {5329-5333},
title = {X-Vectors: Robust DNN Embeddings for Speaker Recognition},
xdoi = {10.1109/ICASSP.2018.8461375}
}

@article{lanckerVan1986,
author = {Van Lancker Sidtis, Diana},
year = {1986},
month = {05},
pages = {},
title = {Familiar voice recognition and unfamiliar voice discrimination are independent and unordered abilities},
volume = {79},
journal = {Journal of The Acoustical Society of America - J ACOUST SOC AMER},
xdoi = {10.1121/1.2023449}
}

@article{dolmenVan1990,
author = {Van Dommelen, Wim},
year = {1990},
pages = {259-72},
title = {Acoustic parameters in human speaker recognition},
volume = {33},
journal = {Lang. Speech},
xdoi = {10.1177/002383099003300302}
}

@article{kreiman1992,
author = {Kreiman, Jody and Gerratt, Bruce and Precoda, Kristin and Berke, Gerald},
year = {1992},
month = {07},
pages = {512-20},
title = {Individual Differences in Voice Quality Perception},
volume = {35},
journal = {Journal of speech and hearing research},
xdoi = {10.1044/jshr.3503.512}
}

@article{baumann2008,
author = {Baumann, Oliver and Belin, Pascal},
year = {2008},
month = {12},
pages = {110-20},
title = {Perceptual scaling of voice identity: Common dimensions for different vowels and speakers},
volume = {74},
journal = {Psychological research},
xdoi = {10.1007/s00426-008-0185-z}
}

@inproceedings{boem2007,
author = {Bőhm, Tamás and Shattuck-Hufnagel, Stefanie},
year = {2007},
month = {01},
pages = {2657-2660},
title = {Utterance-final glottalization as a cue for familiar speaker recognition},
volume = {3}
}

@article{alexander2005,
author = {Alexander, A and Botti, F and Dessimoz, Damien and Drygajlo, Andrzej},
year = {2005},
month = {01},
pages = {S95-9},
title = {The effect of mismatched recording conditions on human and automatic speaker recognition in forensic applications},
volume = {146 Suppl},
journal = {Forensic science international},
xdoi = {10.1016/j.forsciint.2004.09.078}
}

@article{boyle2012,
author = {Boyle, Gregory J.},
year = {2012},
month = {11},
pages = {56-66},
title = {Factor Structure of the Differential Emotions Scale and the Eight State Questionnaire Revisited},
volume = {10},
journal = {The Irish Journal of Psychology},
xdoi = {10.1080/03033910.1989.10557734}
}

@book{janke1978eigenschaftswörterliste,
  title={Die Eigenschaftsw{\"o}rterliste: EWL ; eine mehrdimensionale Methode zur Beschreibung von Aspekten des Befindens},
  author={Janke, W. and Debus, G.},
  number={Bd. 1},
  xurl={https://books.google.de/books?id=BCA-GwAACAAJ},
  year={1978},
  publisher={Verlag f{\"u}r Psychologie Hogrefe}
}

@Inbook{cattell2001,
	author="Cattell, Heather E. P.",
	editor="Dorfman, William I.
	and Hersen, Michel",
	title="The Sixteen Personality Factor (16PF) Questionnaire",
	bookTitle="Understanding Psychological Assessment",
	year="2001",
	publisher="Springer US",
	address="Boston, MA",
	pages="187--215",
	abstract="The Sixteen Personality Factor Questionnaire is a comprehensive measure of normal range personality. Although it was not developed to identify psychopathology, it has been used extensively and productively in clinical settings due to its ability to give a deep, integrated picture of the whole person, including both personal strengths and weaknesses. The 16PF questionnaire can be used to identify patterns of behavior in a wide variety of real-life circumstances. For example, it can be used to understand a person's self-esteem, coping patterns, capacity for empathy, interpersonal needs, likely attitude toward power and authority, cognitive processing style, internalization of societal rules or standards, and likely occupational preferences. Because of this comprehensive scope, 16PF results are useful in a wide variety of settings, including clinical, counseling, industrial, career development, and research.",
	isbn="978-1-4615-1185-4",
	xdoi="10.1007/978-1-4615-1185-4_10",
	xurl="https://xdoi.org/10.1007/978-1-4615-1185-4_10"
	}

@article{zhang2017,
    author = {Zhang, Zixing and Geiger, Jürgen and Pohjalainen, Jouni and Mousa, Amr and Schuller, Björn},
    year = {2017},
    month = {05},
    pages = {},
    title = {Deep Learning for Environmentally Robust Speech Recognition: An Overview of Recent Developments},
    volume = {9},
    journal = {ACM T INTEL SYST TEC},
    xdoi = {10.1145/3178115}
}

@article{nassif2019,
    author = {Nassif, Ali and Shahin, Ismail and Attili, Imtinan and Azzeh, Mohammad and Shaalan, Khaled},
    year = {2019},
    month = {02},
    title = {Speech Recognition Using Deep Neural Networks: A Systematic Review},
    volume = {PP},
    journal = {IEEE Access},
    xdoi = {10.1109/ACCESS.2019.2896880}
}

@article{errattahi2018,
author = {Errattahi, Rahhal and El Hannani, Asmaa and Ouahmane, Hassan},
year = {2018},
month = {01},
pages = {32-37},
title = {Automatic Speech Recognition Errors Detection and Correction: A Review},
volume = {128},
journal = {Procedia Computer Science},
xdoi = {10.1016/j.procs.2018.03.005}
}

@inproceedings{fernandez2017,
author = {Fernández Gallardo, Laura and Möller, Sebastian and Beerends, John},
year = {2017},
month = {08},
booktitle={Proc. Interspeech 2018},
pages = {2939-2943},
title = {Predicting Automatic Speech Recognition Performance Over Communication Channels from Instrumental Speech Quality and Intelligibility Scores},
xdoi = {10.21437/Interspeech.2017-36}
}




@Article{Schuller2011b,
  Title                    = {Recognising realistic emotions and affect in speech: State of the art and lessons learnt from the first challenge},
  Author                   = {Schuller, B. and Batliner, A. and Steidl, S. and Seppi, D.},
  Journal                  = {Speech Commun},
  Pages                    = {1062--1087},
  Volume                   = {53},
  Year                     = {2011},
  Month                    = {11},
  Issue                   = {9-10},
}

@Article{ERinthewild,
  Title                    = {Emotion recognition in the wild},
  Author                   = {Dhall, A. and Goecke, R. and Gedeon T. and Sebe, N.},
  Journal                  = {JMUI},
  Pages                    = {95--97},
  Volume                   = {10},
  Year                     = {2016},
  Issue                   = {2},
}

@Article{Ververidis2006,
  Title                    = {Emotional speech recognition: Resources, features, and methods},
  Author                   = {Dimitrios Ververidis and Constantine Kotropoulos},
  Journal                  = {Speech Commun},
  Pages                    = {1162--1181},
  Volume                   = {48},
  Year                     = {2006},
  Issue                   = {9},
}

@ARTICLE{Tahon2015,
author={M. Tahon and L. Devillers},
journal={EEE/ACM Trans. Audio, Speech, Language Process.},
title={Towards a Small Set of Robust Acoustic Features for Emotion Recognition: Challenges},
year={2016},
volume={24},
number={1},
pages={16-28},
}

@article{AKCAY202056,
title = {Speech emotion recognition: Emotional models, databases, features, preprocessing methods, supporting modalities, and classifiers},
journal = {Speech Communication},
volume = {116},
pages = {56 - 76},
year = {2020},
issn = {0167-6393},
xdoi = {https://xdoi.org/10.1016/j.specom.2019.12.001},
xurl = {http://www.sciencedirect.com/science/article/pii/S0167639319302262},
author = {Mehmet Berkehan Akçay and Kaya Oğuz},
keywords = {Speech emotion recognition, Survey, Speech features, Classification, Speech databases},
abstract = {Speech is the most natural way of expressing ourselves as humans. It is only natural then to extend this communication medium to computer applications. We define speech emotion recognition (SER) systems as a collection of methodologies that process and classify speech signals to detect the embedded emotions. SER is not a new field, it has been around for over two decades, and has regained attention thanks to the recent advancements. These novel studies make use of the advances in all fields of computing and technology, making it necessary to have an update on the current methodologies and techniques that make SER possible. We have identified and discussed distinct areas of SER, provided a detailed survey of current literature of each, and also listed the current challenges.}
}

@INPROCEEDINGS{8733432,
  author={S. K. {Pandey} and H. S. {Shekhawat} and S. R. M. {Prasanna}},
  xbooktitle={2019 29th International Conference Radioelektronika (RADIOELEKTRONIKA)}, 
  booktitle={Int. Conf. Radioelektronika}, 
  title={Deep Learning Techniques for Speech Emotion Recognition: A Review}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
}


@inproceedings{Cho2018,
  author={Jaejin Cho and Raghavendra Pappagari and Purva Kulkarni and Jesús Villalba and Yishay Carmiel and Najim Dehak},
  title={Deep Neural Networks for Emotion Recognition Combining Audio and Transcripts},
  year=2018,
  booktitle={Interspeech},
  pages={247--51},
  xdoi={10.21437/Interspeech.2018-2466},
  xurl={http://dx.xdoi.org/10.21437/Interspeech.2018-2466}
}

@misc{itut1996,
  title={ITU-T Recommendation P.800. Methods for Subjective Determination of Transmission Quality},
  year=1996,
  booktitle={International Telecommunication Union}
}

@misc{itut2019,
  title={ITU-T Recommendation P.808. Subjective evaluation of speech quality with a crowdsourcing approach},
  year=2019,
  booktitle={International Telecommunication Union}
}

@book{waeltermann2013a,
Title = {Dimension-based Quality Modeling of Transmitted Speech},
Author = {Wältermann, Marcel},
Year = {2013},
Address = {Berlin, Heidelberg},
Publisher = {Springer},
Series = {T-Labs Series in Telecommunication Services},
Howpublished = {full},
Toappear = {published},
Categories = {tlabs_yes}
}

@article{wältermann2012direct,			  		  
author={Wältermann, Marcel and Raake, Alexander and Möller, Sebastian},
journal={Journal of the Audio Engineering Society}, 
title={Direct Quantification of Latent Speech Quality Dimensions},
year={2012},
volume={60},
number={4},
pages={246-254},
xdoi={},
month={april}
}	

@article{weiss2018,
author = {Weiss, Benjamin and Estival, Dominique and Stiefelhagen, Ulrike},
year = {2018},
month = {01},
pages = {174-184},
title = {Non-Experts' Perceptual Dimensions of Voice Assessed by Using Direct Comparisons},
volume = {104},
journal = {Acta Acustica united with Acustica},
xdoi = {10.3813/AAA.919157}
}

@inproceedings{Mittag2019,
  author={Gabriel Mittag and Sebastian Möller},
  title={{Quality Degradation Diagnosis for Voice Networks — Estimating the Perceived Noisiness, Coloration, and Discontinuity of Transmitted Speech}},
  year=2019,
  booktitle={Proc. Interspeech 2019},
  pages={3426--3430},
  xdoi={10.21437/Interspeech.2019-2636},
  xurl={http://dx.xdoi.org/10.21437/Interspeech.2019-2636}
}

@inproceedings{pub10309,
    author = {Schwarzenberg, Robert and Harbecke, David and Macketanz, Vivien and Avramidis, Eleftherios and Möller, Sebastian},
    title = {Train, Sort, Explain: Learning to Diagnose Translation Models},
    booktitle = {Proc. NAACL-HLT'19},
    year = {2019},
    publisher = {ACL}
}
@inproceedings{pub9237,
    author = {Zeman, Daniel and Popel, Martin and Straka, Milan and Hajic, Jan and Nivre, Joakim and Ginter, Filip and Luotolahti, Juhani and Pyysalo, Sampo and Petrov, Slav and Potthast, Martin and Tyers, Francis and Badmaeva, Elena and Gokirmak, Memduh and Nedoluzhko, Anna and Cinkova, Silvie and jr., Jan Hajic and Hlavacova, Jaroslava and Kettnerová, Václava and Uresova, Zdenka and Kanerva, Jenna and Ojala, Stina and Missilä, Anna and Manning, Christopher D. and Schuster, Sebastian and Reddy, Dima Taji Siva and Habash, Nizar and Leung, Herman and Marneffe, Marie-Catherine de and Sanguinetti, Manuela and Simi, Maria and Kanayama, Hiroshi and dePaiva, Valeria and Droganova, Kira and Alonso, Héctor Martínez and Çöltekin, Çağrı and Sulubacak, Umut and Uszkoreit, Hans and Macketanz, Vivien and Burchardt, Aljoscha and Harris, Kim and Marheinecke, Katrin and Rehm, Georg and Kayadelen, Tolga and Attia, Mohammed and Elkahky, Ali and Yu, Zhuoran and Pitler, Emily and Lertpradit, Saran and Mandl, Michael and Kirchner, Jesse and Alcalde, Hector Fernandez and Strnadová, Jana and Banerjee, Esha and Manurung, Ruli and Stella, Antonio and Shimada, Atsuko and Kwak, Sookyoung and Mendonca, Gustavo and Lando, Tatiana and Nitisaroj, Rattima and Li, Josie},
    title = {CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies},
    booktitle = {Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Conference on Computational Natural Language Learning (CoNLL-2017), The SIGNLL Conference on Computational Natural Language Learning, August 3-4, Vancouver, BC, Canada},
    year = {2017},
    pages = {1--19},
    publisher = {Association for Computational Linguistics}
}

@article{pub9094,
    author = {Macketanz, Vivien and Avramidis, Eleftherios and Burchardt, Aljoscha and Helcl, Jindrich and Srivastava, Ankit},
    title = {Machine Translation: Phrase-Based, Rule-Based and Neural Approaches with Linguistic Evaluation},
    year = {2017},
    month = {6},
    volume = {17},
    number = {2},
    pages = {28--43},
    journal = {Cybernetics and Information Technologies (cait)},
    publisher = {De Gruyter}
}

@inproceedings{pub9563,
    author = {Avramidis, Eleftherios and Macketanz, Vivien and Lommel, Arle and Uszkoreit, Hans},
    title = {Fine-grained evaluation of Quality Estimation for Machine translation based on a linguistically-motivated Test Suite},
    booktitle = {Proceedings for AMTA 2018 Workshop: Translation Quality Estimation and Automatic Post-Editing. Conference of the Association for Machine Translation in the Americas (AMTA-2018), March 21-21, Boston, United States},
    year = {2018},
    month = {3},
    pages = {243--248},
    publisher = {Association for Machine Translation in the Americas}
}

@book{moeller2014t,
Title = {Quality of Experience: Advanced Concepts, Applications and Methods},
Author = {Möller, Sebastian and Raake, Alexander},
Year = {2014},
Isbn = {978-3-319-02681-7},
xdoi = {10.1007/978-3-319-02681-7},
Address = {Heidelberg},
Publisher = {Springer},
Abstract = {This pioneering book develops definitions and concepts related to Quality of Experience in the context of multimedia- and telecommunications-related applications, systems and services and applies these to various fields of communication and media technologies. The editors bring together numerous key-protagonists of the new discipline ``Quality of Experience'' and combine the state-of-the-art knowledge in one single volume.},
xurl = {https://www.qu.tu-berlin.de/fileadmin/fg41/publications-restricted/moeller_2014_quality-of-experience.-advanced-concepts.-applications-and-methods.pdf}
}

@book{polzehl2014a,
Title = {Personality in Speech - Assessment and Automatic Classification},
Author = {Polzehl, Tim},
Booktitle = {T-Labs Series in Telecommunication Services},
Year = {2014},
Isbn = {978-3-319-09516-5},
Publisher = {Springer},
Series = {XIV},
Toappear = {published}
}

@book{fernandez2016,
title = {Human and Automatic Speaker Recognition over Telecommunication Channels},
author = {F Gallardo, Laura},
Booktitle = {T-Labs Series in Telecommunication Services},
Year = {2016},
Publisher = {Springer},
}


@article{moeller2017j,
author = {Möller, Sebastian and Köster, Friedemann},
year = {2017},
month = {12},
pages = {},
title = {Review of recent standardization activities in speech quality of experience},
volume = {2},
journal = {Quality and User Experience},
xdoi = {10.1007/s41233-017-0012-7}
}

@TechReport{GEW,
  Title                    = {{Geneva Emotion Wheel rating study}},
  Author                   = {Sacharin, V. and Schlegel, K. and and Scherer, K. R.},
  Institution              = {Center for Person, Kommunikation, Aalborg University},
  Year                     = {2012},
  Address                  = {NCCR Affective Sciences},
}


@article{moeller2013ii,
author = {Möller, Sebastian and Heusdens, R.},
year = {2013},
month = {09},
pages = {1955-1967},
title = {Objective Estimation of Speech Quality for Communication Systems},
volume = {101},
journal = {Proceedings of the IEEE},
xdoi = {10.1109/JPROC.2013.2241374}
}
@inproceedings{burkhardt2017a,
Title = {Complex Emotions -- The Simultaneous Simulation of Emotion-Related States In Synthesized Speech},
Author = {Burkhardt, Felix and Weiss, Benjamin},
Booktitle = {28\textsuperscript{th} Konferenz Elektronische Sprachsignalverarbeitung (ESSV)},
Pages = {67--74},
Year = {2017},
Isbn = {978-3-95908-094-1},
xAddress = {Dresden},
xEditor = {Möbius, B. and Steiner, I. and Trouvain, J.},
xPublisher = {TUDpress},
Howpublished = {full},
xurl = {https://www.qu.tu-berlin.de/fileadmin/fg41/publications-restricted/burkhardt_2017_complex-emotions-..-the-simultaneous-simulation-of-emotion.related-states-in-synthesized-speech.pdf},
xurl2 = {http://essv2017.coli.uni-saarland.de/pdfs/Burkhardt.pdf},
Reviewed = {no},
Toappear = {published}
}

@INPROCEEDINGS{7351631,
  author={G. {Letournel} and A. {Bugeau} and V. -. {Ta} and J. -. {Domenger}},
  booktitle={2015 IEEE ICIP'15}, 
  title={Face de-identification with expressions preservation}, 
  year={2015},
  volume={},
  number={},
  pages={4366-4370},
  }


@Inbook{Aggarwal2008,
author="Aggarwal, Charu C.
and Yu, Philip S.",
editor="Aggarwal, Charu C.
and Yu, Philip S.",
title="A General Survey of Privacy-Preserving Data Mining Models and Algorithms",
bookTitle="Privacy-Preserving Data Mining: Models and Algorithms",
year="2008",
publisher="Springer US",
address="Boston, MA",
pages="11--52",
abstract="In recent years, privacy-preserving data mining has been studied extensively, because of the wide proliferation of sensitive information on the internet. A number of algorithmic techniques have been designed for privacy-preserving data mining. In this paper, we provide a review of the state-of-the-art methods for privacy. We discuss methods for randomization, k-anonymization, and distributed privacy-preserving data mining. We also discuss cases in which the output of data mining applications needs to be sanitized for privacy-preservation purposes. We discuss the computational and theoretical limits associated with privacy-preservation over high dimensional data sets.",
isbn="978-0-387-70992-5",
xdoi="10.1007/978-0-387-70992-5_2",
xurl="https://xdoi.org/10.1007/978-0-387-70992-5_2"
}

@Incollection{BremNiebuhr2020,
  Title                    = {Dress to impress? On the interaction of attire with prosody and gender in the perception of speaker charisma},
  Address                  = {New York},
  Author                   = {A. Brem and O. Niebuhr},
  Booktitle                = {Voice attractiveness: Concepts, methods, and data},
  Pages                    = {301--309},
  Year                     = {2020},
}%Editor                   = {B. Weiß and J. Trouvain and J. Ohala},

@inproceedings{pub11064,
    author = {Schwarzenberg, Robert and Castle, Steffen},
    title = {Pattern-Guided Integrated Gradients},
    booktitle = {Proceedings of the ICML 2020 Workshop on Human Interpretability in Machine Learning (WHI)},
    year = {2020},
    publisher = {ICML}
}
@inproceedings{pub9964,
    author = {Harbecke, David and Schwarzenberg, Robert and Alt, Christoph},
    title = {Learning Explanations From Language Data},
    booktitle = {EMNLP Workshop on Interpreting and Analysing Neural Networks for NLP (BlackboxNLP). Conference on Emperical Methods in Natural Language Processing (EMNLP-2018), October 31-November 4, Brussels, Belgium},
    year = {2018},
    publisher = {EMNLP}
}

@Article{SiegertJMUI:2013,
  Title                    = {{Inter-Rater Reliability for Emotion Annotation in Human-Computer Interaction -- Comparison and Methodological Improvements}},
  Author                   = {Ingo Siegert and Ronald Böck and Andreas Wendemuth},
  Journal                  = {Journal of Multimodal User Interfaces},
  Pages                    = {17--28},
  Volume                   = {8},
  Year                     = {2014},
  Issue                   = {1},

  Keyword                  = {pubown},
  
  Owner                    = {papaingo},
  Timestamp                = {2014.08.10}
}

@inproceedings{engel2020self,
  title={Self-supervised Pitch Detection by Inverse Audio Synthesis},
  author={Engel, Jesse and Swavely, Rigel and Hantrakul, Lamtharn Hanoi and Roberts, Adam and Hawthorne, Curtis},
  xbooktitle={International Conference on Machine Learning (ICML'20)},
  year={2020}
}

@ARTICLE{bellur2020taslp,
  author={A. {Bellur} and M. {Elhilali}},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  title={Audio object classification using distributed beliefs and attention},
  year={2020},
  volume={},
  number={},
  pages={1-1},
  xdoi={10.1109/TASLP.2020.2966867}
}

@inproceedings{kothinti2019joint,
  title={Joint acoustic and class inference for weakly supervised sound event detection},
  author={Kothinti, Sandeep and Imoto, Keisuke and Chakrabarty, Debmalya and Sell, Gregory and Watanabe, Shinji and Elhilali, Mounya},
  booktitle={ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={36--40},
  year={2019},
  organization={IEEE}
}

@article{chakrabarty2019gestalt,
  title={A Gestalt inference model for auditory scene segregation},
  author={Chakrabarty, Debmalya and Elhilali, Mounya},
  journal={PLoS computational biology},
  volume={15},
  number={1},
  pages={e1006711},
  year={2019},
  publisher={Public Library of Science}
}

@article{parkjoint2020dcase,
  title={Joint Acoustic and Supervised Inference for Sound Event Detection},
  author={Park, Sangwook and Bellur, Ashwin and Kothinti, Sandeep and Kapourchali, Masoumeh Heidari and Elhilali, Mounya}
}

@incollection{elhilali2019modulation,
  title={Modulation representations for speech and music},
  author={Elhilali, Mounya},
  booktitle={Timbre: Acoustics, perception, and cognition},
  pages={335--359},
  year={2019},
  publisher={Springer}
}

@inproceedings{bellur2020bio,
  title={Bio-Mimetic Attentional Feedback in Music Source Separation},
  author={Bellur, Ashwin and Elhilali, Mounya},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={8718--8722},
  year={2020},
  organization={IEEE}
}

@article{stober2015arXiv:1511.04306,
  author = {Sebastian Stober and Avital Sternin and Adrian M. Owen and Jessica A. Grahn},
  title = {Deep Feature Learning for {EEG} Recordings},
  journal = {arXiv preprint arXiv:1511.04306},
  year = {2015},
  note = {submitted as conference paper for ICLR 2016},
  xurl = {http://arxiv.org/abs/1511.04306}
}